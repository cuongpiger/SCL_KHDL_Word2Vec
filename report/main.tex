\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{multirow}
\usepackage[utf8]{vietnam}
\usepackage{tipa}
\usepackage{float}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
  literate=%
    {đ}{{\dj}}1
    {â}{{\^a}}1
    {ă}{{\u{a}}}1
    {ê}{{\^e}}1
    {ô}{{\^o}}1
    {ơ}{{\ohorn}}1
    {ư}{{\uhorn}}1
    {á}{{\'a}}1
    {à}{{\`a}}1
    {ả}{\h{a}}1
    {ã}{{\~a}}1
    {ạ}{\textsubdot{a}}1
    {ấ}{\'{\^a}}1
    {ầ}{\`{\^a}}1
    {ẩ}{\h{\^a}}1
    {ẫ}{\~{\^a}}1
    {ậ}{\textsubdot{\^a}}1
    {ắ}{\'{\u{a}}}1
    {ằ}{\`{\u{a}}}1
    {ẳ}{\h{\u{a}}}1
    {ẵ}{\~{\u{a}}}1
    {ặ}{\textsubdot{\u{a}}}1
    {é}{{\'e}}1
    {è}{{\`e}}1
    {ẻ}{\h{e}}1
    {ẽ}{{\~e}}1
    {ẹ}{\textsubdot{e}}1
    {ế}{\'{\^e}}1
    {ề}{\`{\^e}}1
    {ể}{\h{\^e}}1
    {ễ}{\~{\^e}}1
    {ệ}{\textsubdot{\^{e}}}1
    {í}{{\'i}}1
    {ì}{{\`i}}1
    {ỉ}{\h{i}}1
    {ĩ}{{\~i}}1
    {ị}{\textsubdot{i}}1
    {ó}{{\'o}}1
    {ò}{{\`o}}1
    {ỏ}{\h{o}}1
    {õ}{{\~o}}1
    {ọ}{\textsubdot{o}}1
    {ố}{\'{\^o}}1
    {ồ}{\`{\^o}}1
    {ổ}{\h{\^o}}1
    {ỗ}{\~{\^o}}1
    {ộ}{\textsubdot{\^o}}1
    {ớ}{\'{\ohorn}}1
    {ờ}{\`{\ohorn}}1
    {ở}{\h{\ohorn}}1
    {ỡ}{\~{\ohorn}}1
    {ợ}{\textsubdot{\ohorn}}1
    {ú}{{\'u}}1
    {ù}{{\`u}}1
    {ủ}{\h{u}}1
    {ũ}{{\~u}}1
    {ụ}{\textsubdot{u}}1
    {ứ}{\'{\uhorn}}1
    {ừ}{\`{\uhorn}}1
    {ử}{\h{\uhorn}}1
    {ữ}{\~{\uhorn}}1
    {ự}{\textsubdot{\uhorn}}1
    {ý}{{\'y}}1
    {ỳ}{{\`y}}1
    {ỷ}{\h{y}}1
    {ỹ}{{\~y}}1
    {ỵ}{\textsubdot{y}}1
    {Đ}{{\DJ}}1
    {Â}{{\^A}}1
    {Ă}{{\u{A}}}1
    {Ê}{{\^E}}1
    {Ô}{{\^O}}1
    {Ơ}{{\OHORN}}1
    {Ư}{{\UHORN}}1
    {Á}{{\'A}}1
    {À}{{\`A}}1
    {Ả}{\h{A}}1
    {Ã}{{\~A}}1
    {Ạ}{\textsubdot{A}}1
    {Ấ}{\'{\^A}}1
    {Ầ}{\`{\^A}}1
    {Ẩ}{\h{\^A}}1
    {Ẫ}{\~{\^A}}1
    {Ậ}{\textsubdot{\^A}}1
    {Ắ}{\'{\u{A}}}1
    {Ằ}{\`{\u{A}}}1
    {Ẳ}{\h{\u{A}}}1
    {Ẵ}{\~{\u{A}}}1
    {Ặ}{\textsubdot{\u{A}}}1
    {É}{{\'E}}1
    {È}{{\`E}}1
    {Ẻ}{\h{E}}1
    {Ẽ}{{\~E}}1
    {Ẹ}{\textsubdot{E}}1
    {Ế}{\'{\^E}}1
    {Ề}{\`{\^E}}1
    {Ể}{\h{\^E}}1
    {Ễ}{\~{\^E}}1
    {Ệ}{\textsubdot{\^{E}}}1
    {Í}{{\'I}}1
    {Ì}{{\`I}}1
    {Ỉ}{\h{I}}1
    {Ĩ}{{\~I}}1
    {Ị}{\textsubdot{I}}1
    {Ó}{{\'O}}1
    {Ò}{{\`O}}1
    {Ỏ}{\h{O}}1
    {Õ}{{\~O}}1
    {Ọ}{\textsubdot{O}}1
    {Ố}{\'{\^O}}1
    {Ồ}{\`{\^O}}1
    {Ổ}{\h{\^O}}1
    {Ỗ}{\~{\^O}}1
    {Ộ}{\textsubdot{\^O}}1
    {Ớ}{\'{\OHORN}}1
    {Ờ}{\`{\OHORN}}1
    {Ở}{\h{\OHORN}}1
    {Ỡ}{\~{\OHORN}}1
    {Ợ}{\textsubdot{\OHORN}}1
    {Ú}{{\'U}}1
    {Ù}{{\`U}}1
    {Ủ}{\h{U}}1
    {Ũ}{{\~U}}1
    {Ụ}{\textsubdot{U}}1
    {Ứ}{\'{\UHORN}}1
    {Ừ}{\`{\UHORN}}1
    {Ử}{\h{\UHORN}}1
    {Ữ}{\~{\UHORN}}1
    {Ự}{\textsubdot{\UHORN}}1
    {Ý}{{\'Y}}1
    {Ỳ}{{\`Y}}1
    {Ỷ}{\h{Y}}1
    {Ỹ}{{\~Y}}1
    {Ỵ}{\textsubdot{Y}}1}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{listings}
\usepackage{indentfirst}
\lstset{basicstyle=\ttfamily, showstringspaces=false, commentstyle=\color{red}, keywordstyle=\color{blue}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}
            {-2.5ex\@plus -1ex \@minus -.25ex}
            {1.25ex \@plus .25ex}
            {\normalfont\normalsize\bfseries}}
\makeatother
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}


\newcommand{\leftIndent}{\setlength{\parindent}{0.6cm}}
\newcommand{\lleftIndent}{\setlength{\parindent}{1.2cm}}
\newcommand{\itemsizePaddingLeft}{\setlength{\itemindent}{0.6cm}}
\newcommand{\includeImage}[3]{
\begin{figure}[H]
  \centering
  \includegraphics[width=#1\textwidth]{images/#2.png}
  \def\temp{#3}\ifx\temp\empty\else\caption{#3}\fi
\end{figure}}

\begin{document}
\begin{titlepage}

  \newcommand{\HRule}{\rule{\linewidth}{0.5mm}} 
  
  \center
  
  \textsc{\LARGE Đại học Khoa học tự nhiên}\\[1.5cm] 
  \textsc{\Large Môn học: Khoa Học Dữ Liệu}\\[0.5cm] 
  \textsc{\large Báo cáo đồ án cuối kỳ}\\[0.5cm] 
  
  \HRule \\[0.4cm]
  { \huge \bfseries Word2Vec}\\[0.4cm]
  \HRule \\[1.5cm]

  \begin{minipage}{0.4\textwidth}
  \begin{flushleft} \large
  \emph{\textbf{Giảng viên}}\\
  Nguyễn Ngọc Đức 
  \end{flushleft}
  \end{minipage}
  ~
  \begin{minipage}{0.4\textwidth}
  \begin{flushright}
    \large \emph{\\[3cm]\textbf{Sinh viên}} \\
    20424008 - Dương Mạnh Cường
  \end{flushright}
  \end{minipage}\\[2cm]

  \includegraphics{./images/logo_hcmus.png}\\[1cm]
  \vfill

  \today
  
  \end{titlepage}

\tableofcontents
\newpage

Neural network yêu cầu đầu vào ở dạng \textbf{numeric}. Cho nên, khi ta có dữ liệu dạng \textbf{text}, ta cần chuyển đổi chúng thành dữ liệu dạng numeric.\\

\indent Có nhiều phương pháp khác nhau để chuyển đổi dữ liệu dạng text sang numeric mà phổ biến nhất là:
\begin{itemize}
  \setlength{\itemindent}{0.6cm}
  \item Term frequency-inverse document frequency (TF-IDF).
  \item Bag of words (BOW).
\end{itemize}

\vskip 0.5cm
\indent Tuy nhiên, điểm yếu của hai phương pháp trên là chúng \textbf{không nắm bắt được ngữ nghĩa của từ}, nói cách khác là chúng không hiểu được ý nghĩa của từ.\\

\indent Có nhiều cách khắc phục nhược điểm này, mà một trong những cách đó là sử dụng \textbf{Word2Vec} bằng cách đại diện cho từng từ bằng một \textbf{vector} trong không gian $m$ chiều. Lúc này, các từ có nghĩa tương đồng nhau sẽ nằm gần nhau.

\includeImage{0.4}{01}{Các từ có ý nghĩa tương đồng nhau nằm gần nhau.}

\section{Word2Vec model}
Word2Vec là một trong những phương pháp \textbf{word embedding} được sử dụng phổ biến.\\

\indent Word embedding là cách ta biểu diễn các \textbf{word vector} trong không gian vector.\\

\indent Các word vector được tạo ra bởi Word2Vec model có khả năng nắm bắt được các \textbf{semantic} \textit{(ngữ nghĩa)} và \textbf{syntactic} \textit{(ý nghĩa cú pháp)} của từ.\\

\includeImage{1}{03}{Ví dụ về \textbf{semantic} và \textbf{syntactic}.}

\indent Ví dụ có câu: \textsl{"Archie used to live in New York, he then moved to Santa Clara. He loves apples and strawberries."}.\\

\indent Word2Vec model sẽ phát sinh các vector cho từng từ trong văn bản. Nếu chúng ta trực quan các vector này trong không gian vector tương ứng, chúng ta có thể thấy các từ tương tự nhau sẽ nằm gần nhau.

\includeImage{0.95}{02}{Các từ trong câu ví dụ được biểu diễn trong không gian vector}
\begin{tcolorbox}[grow to left by=-0.6cm]
  \textbf{Nhận xét}
  \begin{itemize}
    \item Ở đây các cặp từ như \textsl{apples} - \textsl{strawberries}, \textsl{New York} - \textsl{Santa Clara} có ý nghĩa tương đồng nhau nên nằm gần nhau.
  \end{itemize}
\end{tcolorbox}

\vskip 0.5cm
\indent Do đó, với Word2Vec model có thể học cách biểu diễn các vector giúp cho neural network có thể hiểu được ý nghĩa của từ tương ứng với vector đó.\\

\indent Và vì chúng ta có thể hiểu được semantic và syntactic của từ điều này giúp ta tận dụng các vector này vào các bài toán như \textbf{text summarization} \textit{(tóm tắt văn bản)}, \textbf{sentiment analysis} \textit{(phân tích tình cảm)}, \textbf{text generation} \textit{(tạo văn bản)},...\\

\indent Có hai cách để xây dựng Word2Vec model:
\begin{enumerate}
  \itemsizePaddingLeft
  \item \textbf{CBOW model}.
  \item \textbf{Skip-gram model}.
\end{enumerate}

\subsection{CBOW model}
Giả sử chúng ta có một neural network bao gồm: \textbf{một input layer}, \textbf{một hidden layer} và \textbf{một output layer}. Mục đích của network này là dự đoán ra \textbf{một từ} dựa vào \textbf{các từ xung quanh nó}. Từ mà chúng ta cố gắng dự đoán được gọi là \textbf{target word} và các từ xung quanh nó được gọi là \textbf{context word}.\\

\indent Vậy chúng ta cần bao nhiêu context word để dự đoán ra target word? Chúng ta sẽ sử dụng một \textbf{window} \textit{(cửa sổ)} có kích thước là $n$ để chọn các context word. Nếu $n = 2$ thì chúng ta sẽ sử dụng hai từ \textbf{phía trước} và \textbf{phía sau} của target word làm các context word.\\

\indent Xem xét câu sau: \textsl{"The Sun rises in the east."} với \textsl{rises} là target word. Nếu chúng ta xét kích thước của window là $2$ thì chúng ta sẽ lấy hai từ phía trước là \textsl{The}, \textsl{Sun} và hai từ phía sau là \textsl{in}, \textsl{the} của target word làm các context word.\\

\includeImage{0.7}{04}{Target word và context word trong CBOW model.}

\indent Lúc này input của network là các context word và output của network là target word. Và vì neural network chỉ chấp nhận input là numeric data nên chúng ta sẽ sử dụng kỹ thuật \textbf{one-hot encoding} để chuyển đổi các text data thành numeric data.

\includeImage{0.6}{05}{One-hot encoding cho text data.}

\indent Kiến trúc của CBOW model được thể hiện dưới hình sau. Ở đây các context word là: \textsl{the}, \textsl{sun}, \textsl{in} và \textsl{east} được dùng làm đầu vào cho network và dự đoán ra target word là \textsl{rises} ở đầu ra.

\includeImage{0.99}{06}{Kiến trúc của CBOW model.}

\indent Ở vài lần lặp đầu tiên, network không thể dự đoán target word một cách chính xác. Nhưng sau một loạt các vòng lặp bằng cách sử dụng \textbf{gradient descent}, các \textbf{weight} \textit{(trọng số)} của network được cập nhật và tìm ra được \textbf{optimal weight} \textit{(trọng số thích hợp)} để dự đoán ra target word một cách chính xác.

\vskip 0.5cm
\indent Vì chúng ta có một input layer, một hidden layer và một output layer, nên chúng ta sẽ có hai weight:
\begin{enumerate}
  \itemsizePaddingLeft
  \item Weight từ input layer đến hidden layer - $\boldsymbol{W}$.
  \item Weight từ hidden layer đến output layer - $\boldsymbol{W'}$.
\end{enumerate}

\indent Trong quá trình đào tạo network, các weight sẽ được cập nhật trong quá trình back propagation nhằm tìm ra optimal weight cho hai bộ $\boldsymbol{W}$ và $\boldsymbol{W'}$.

\vskip 0.5cm
\indent Về sau, weight set giữa input layer và hidden layer $\boldsymbol{W}$ được cập nhật và tối ưu tạo thành các vector đại diện cho các từ của input layer.\\

\indent Sau khi kết thúc quá trình đào tạo, chúng ta chỉ cần loại bỏ output layer và lấy ra weight set giữa input layer và hidden layer và gán chúng cho các từ tương ứng.\\

\indent Dưới đây là các vector tương ứng cho các từ của $\boldsymbol{W}$. Word embedding tương ứng cho từ \textsl{sun} là $\begin{bmatrix} 0.0 & 0.3 & 0.3 & 0.6 & 0.1 \\ \end{bmatrix}$.

$$\boldsymbol{W} = \text{ } \begin{matrix} the \\ sun \\ rises \\ in \\ east \end{matrix} \begin{bmatrix} 0.01 & 0.02 & 0.1 & 0.5 & 0.37 \\ 0.0 & 0.3 & 0.3 & 0.6 & 0.1 \\ 0.4 & 0.34 & 0.11 & 0.61 & 0.43 \\ 0.1 & 0.11 & 0.1 & 0.17 & 0.369 \\ 0.33 & 0.4 & 0.3 & 0.17 & 0.1 \\ \end{bmatrix}$$

\subsubsection{CBOW model với một context word}
CBOW model cần một số lượng context word $C$ nhất định để dự đoán target word. Ở phần này chúng ta sẽ xem xét trường hợp chỉ sử dụng duy nhất một context word, tức $C = 1$. Lúc này netword nhận vào một context word ở đầu vào và trả về một target word ở đầu ra.

\end{document}
